# -*- coding: utf-8 -*-
"""Nuri Hidayatuloh-Submission1_Machine Learning Intermediate Lv_Lintasarta Cloudeka Digischool & Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kmBzapwCe8wg6pzyB11ME2bSnwzQzQ5X

**IMPORT LIBRARY YANG DIBUTUHKAN**
"""

import pandas as pd
import numpy as np
import json
from sklearn.model_selection import train_test_split
import nltk
from nltk.corpus import stopwords
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt

!wget https://raw.githubusercontent.com/NewReyy/NLP-KlasifikasiBerita/main/bbc-text.csv

"""**LOAD DATASET**"""

df = pd.read_csv("bbc-text.csv")
df.head()

df.head()

df.info()

count = df['category'].value_counts()
print("Jumlah kelas atau category:")
for category, jumlah in count.items():
    print(f"{category}: {jumlah}")

import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
nltk.download('wordnet')

"""**PREPROCESSING**"""

df_clean = df.copy()

df_clean

"""**CASE FOLDING**"""

df_clean.text = df_clean.text.apply(lambda x: x.lower())

import nltk, os, re, string

"""**MEMBUAT FUNGSI CLEANER UNTUK MENGHAPUS TANDA BACA DARI DATA TEKS**"""

def cleaner(data):
    return(data.translate(str.maketrans('','', string.punctuation)))
df_clean.text = df_clean.text.apply(lambda x: cleaner(x))

"""**LEMMATIZER UNTUK MERUBAH KEDALAM BENTUK ASLI**"""

from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet as wn

lemmatizer = WordNetLemmatizer()

def lem(data):
    pos_dict = {'N': wn.NOUN, 'V': wn.VERB, 'J': wn.ADJ, 'R': wn.ADV}
    return(' '.join([lemmatizer.lemmatize(w,pos_dict.get(t, wn.NOUN)) for w,t in nltk.pos_tag(data.split())]))
df_clean.text = df_clean.text.apply(lambda x: lem(x))

"""**REM NUMBER UNTUK MENGHAPUS ANGKA**"""

def rem_numbers(data):
    return re.sub('[0-9]+','',data)
df_clean.text = df_clean.text.apply(lambda x: rem_numbers(x))

"""**STOPWORDS UNTUK MENGHAPUS KATA-KATA UMUM**"""

from nltk.corpus import stopwords
stop_word = set(stopwords.words('english'))
def stopword(data):
    return ' '.join([w for w in data.split() if w not in stop_word])
df_clean.loc[:, 'text'] = df_clean['text'].apply(lambda x: stopword(x))

"""**MENAMPILKAN DATA PREPROCESSING**"""

df_clean

"""**MODELLING**
#### ONE HOT ENCODING
"""

category = pd.get_dummies(df_clean.category)
df_new = pd.concat([df_clean, category], axis=1)
df_new = df_new.drop(columns='category')

df_new

"""#### SPLITTING DATA & TOKENIZER"""

X = df_new['text'].values
Y = df_new[['business', 'entertainment', 'politics', 'sport', 'tech']].values

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x',
                      filters='!"#$%&()*+,-./:;<=>@[\]^_`{|}~ ')

tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

seq_train = tokenizer.texts_to_sequences(X_train)
seq_test = tokenizer.texts_to_sequences(X_test)

padded_train = pad_sequences(seq_train)
padded_test = pad_sequences(seq_test)

"""#### ARSITEKTUR MODEL"""

#Import TensorFlow:
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam

model = Sequential([
    Embedding(input_dim=5000, output_dim=64),
    LSTM(128),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(5, activation='softmax')
])

# Compile model dengan optimizer Adam dan learning rate yang dapat diatur
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

class berhenti(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if logs.get('accuracy') > 0.9 and logs.get('val_accuracy') > 0.9:
      print('\nAkurasi sudah mencapai lebih dari 90%')
      self.model.stop_training = True
Callback = berhenti()

history = model.fit(padded_train, Y_train,
                    epochs = 20,
                    validation_data = (padded_test, Y_test), # menampilkan akurasi pengujian data validasi
                    verbose = 2,
                    callbacks = [Callback],
                    validation_steps = 30)

"""#### **VISUALIZATION GRAPH**"""

#UNTUK MENAMPILKAN GRAFIK ACCURACY
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('ACCURACY MODEL')
plt.ylabel('ACCURACY')
plt.xlabel('LOSS')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#UNTUK MENAMPILKAN GRAFIK LOSS
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('LOSS MODEL')
plt.ylabel('LOSS')
plt.xlabel('EPOCH')
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(['train', 'test'], loc='upper left')
plt.show()